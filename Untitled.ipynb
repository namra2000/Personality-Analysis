{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7875d3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import string\n",
    "from difflib import SequenceMatcher\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import csv\n",
    "from nltk import wordnet\n",
    "from textblob import TextBlob\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a4d6400",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(textdata):\n",
    "    processedText = []\n",
    "    # Create Lemmatizer and Stemmer\n",
    "    wordLemm = WordNetLemmatizer()\n",
    "    # Regex patterns\n",
    "    emoji=r'\\\\u[1F600-1F6FF]'\n",
    "    urlPattern = r\"((http://)[^ ]*|(https://)[^ ]*|( www\\.)[^ ]*)\"\n",
    "    userPattern       = '@[^\\s]+'\n",
    "    alphaPattern      = \"[^a-zA-Z0-9]\"\n",
    "    sequencePattern   = r\"(.)\\1\\1+\"\n",
    "    seqReplacePattern = r\"\\1\\1\"\n",
    "    for tweet in textdata:\n",
    "        tweet = tweet.lower()\n",
    "        # Replace all URls with 'URL'\n",
    "        tweet = re.sub(urlPattern,' ',tweet)\n",
    "        # Replace all emojis.\n",
    "        tweet = re.sub(emoji, ' ' ,tweet)        \n",
    "        # Replace @USERNAME to 'USER'.\n",
    "        tweet = re.sub(userPattern,' ', tweet)        \n",
    "        # Replace all non alphabets.\n",
    "        tweet = re.sub(alphaPattern, \" \", tweet)\n",
    "        # Replace 3 or more consecutive letters by 2 letter.\n",
    "        tweet = re.sub(sequencePattern, seqReplacePattern, tweet)\n",
    "        tweetwords = ''\n",
    "        for word in tweet.split():\n",
    "            # Checking if the word is a stopword.\n",
    "            # If word not in stopwordlist\n",
    "            if len(word)>1:\n",
    "                \n",
    "                word = wordLemm.lemmatize(word)\n",
    "            \n",
    "                tweetwords += (word+' ')\n",
    "        processedText.append(tweetwords)\n",
    "        \n",
    "    return processedText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe69235f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models():\n",
    "    '''\n",
    "    Replace '..path/' by the path of the saved models.\n",
    "    '''\n",
    "    \n",
    "    # Load the vectoriser.\n",
    "    file = open('..path/vectoriser-ngram-(1,2).pickle', 'rb')\n",
    "    vectoriser = pickle.load(file)\n",
    "    file.close()\n",
    "    # Load the LR Model.\n",
    "    file = open('..path/Sentiment-LRv1.pickle', 'rb')\n",
    "    LRmodel = pickle.load(file)\n",
    "    file.close()\n",
    "\n",
    "    # Load the Random Forest Model.\n",
    "    file = open('..path/Sentiment-RF.pickle', 'rb')\n",
    "    RFmodel = pickle.load(file)\n",
    "    file.close()\n",
    "    \n",
    "    # Load the Support Vector Model.\n",
    "    file = open('..path/Sentiment-Svc.pickle', 'rb')\n",
    "    SVmodel = pickle.load(file)\n",
    "    file.close()\n",
    "    \n",
    "    return vectoriser, LRmodel,RFmodel,SVmodel\n",
    "\n",
    "def predict(vectoriser, model, text):\n",
    "    # Predict the sentiment\n",
    "    textdata = vectorizer.transform(preprocess(text))\n",
    "    sentiment = model.predict(textdata)\n",
    "    \n",
    "    # Make a list of text with sentiment.\n",
    "    data = []\n",
    "    for text, pred in zip(text,sentiment):\n",
    "        data.append((text,pred))\n",
    "        \n",
    "    # Convert the list into a Pandas DataFrame.\n",
    "    df = pd.DataFrame(data, columns = ['Text','Sentiment'])\n",
    "    df = df.replace([0,1,2], [\"Extrovert\",\"Introvert\",\"Neutral\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ce7c71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import *\n",
    "from tkinter import simpledialog\n",
    "from tkinter import messagebox\n",
    "import tkinter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db34dcf9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-99ab347d2db2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mUSER_INP\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msimpledialog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maskstring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Personality Prediction\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Enter Your Text:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mUSER_INP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLRmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;31m# check it out\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Sentiment'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "ROOT = tk.Tk()\n",
    "text=[]\n",
    "ROOT.withdraw()\n",
    "ROOT.geometry(\"700x500\")\n",
    "USER_INP = simpledialog.askstring(title=\"Personality Prediction\",prompt=\"Enter Your Text:\") \n",
    "text.append(USER_INP)\n",
    "vectorizer,LRmodel,RFmodelS\n",
    "df = predict(vectorizer, LRmodel, text)\n",
    "# check it out\n",
    "data=df['Sentiment']\n",
    "tkinter.messagebox.showinfo('Prediction',data.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c829072",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
